import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pylab as plt

# Draw u from Gaussian(0,1), i = 1,...,10 (unknown to agent) 
# arms = number of possible of actions (known to agent)
arms = 10
u = np.random.randn(arms,1) 

# Rewards of action i at time t => x_i(t) ~ N(u_i,1)
# x_i(t) is itself randomly drawn, so it's not deterministic
rounds = 20
x = np.zeros((rounds,1))

# Initialize Q: agent's record of rewards
# Initialize estQ: agent's estimate of rewards
Q = np.zeros((arms, rounds))
estQ = np.zeros((arms,1))

# Initialize the first column of Q with randomly drawn "expectations" 
# Set probability of exploring at whatever %. 
Q[:,0] = np.random.randn(arms) 
exploreProbability = 0.2

for time in range(rounds): 
  
    # We first cycle through each arm and estimate our belief of that arm. 
    # The belief is defined as Q_t(a) = sum of rewards prior to t / number of times action was taken.
    for i in range(arms): 
        estQ[i] = sum(Q[i,:])/np.count_nonzero(Q[i,:])
    
    if np.random.uniform(0,1) > exploreProbability: 
        
        # argmax(estQ) chooses the row (arm) with the highest value
        # np.random.normal(u[chosenLever],1) generates N(u_i,1) 
        chosenLever = np.argmax(estQ) 
        Q[chosenLever, time] = np.random.normal(u[chosenLever],1)
        
        
    else: # go exploring
        chosenLever = np.random.choice(arms)
        Q[chosenLever, time] = np.random.normal(u[chosenLever],1)


# Create the plot. 
ax = sns.heatmap(Q, annot = False, cmap="YlGnBu") #, linewidth=0)
plt.show()
