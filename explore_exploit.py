# Draw u from Gaussian(0,1), i = 1,...,10 (unknown to agent) 
# arms = number of possible of actions (known to agent)
arms = 10
u = np.random.randn(arms,1) 

# Rewards of action i at time t => x_i(t) ~ N(u_i,1)
# x_i(t) is itself randomly drawn, so it's not deterministic
rounds = 5 
x = np.zeros((rounds,1))

# Initialize Q => agent's record of rewards
# Initialize estQ => agent's estimate of rewards
Q = np.zeros((arms, rounds))

# Maybe initialize the first column of Q... not sure
Q[:,0] = np.random.randn(arms)

estQ = np.zeros((arms,1))
Q[2,3] = 5

for time in x: 
    
    # Check the updated expectations
    for estimate in range(arms): 
        
        # Q_t(a) = sum of rewards prior to t / number of time a was taken
        estQ[estimate] = sum(Q[estimate,:])/np.count_nonzero(Q[estimate,:])
        # chosenLever = np.argmax(estQ) 
        
        
print(Q)
print(estQ)
print(np.argmax(estQ))



